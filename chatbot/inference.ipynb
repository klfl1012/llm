{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian/Documents/github/llm/.venv-llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load(\"fused_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import generate\n",
    "\n",
    "\n",
    "INIT_PROMPT = (\n",
    "    \"Du bist ein hochentwickelter KI-Schreibassistent, der professionelle, präzise und technische Texte in \"\n",
    "    \"in Deutsch und Englisch verfasst. Falls der Benutzer keine Sprache angibt, nutze die Sprache der Eingabe.\\n\\n\"\n",
    ")\n",
    "\n",
    "def generate_response(instruction):\n",
    "    instruction = INIT_PROMPT + instruction\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": instruction},\n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, max_length=4000) \n",
    "\n",
    "    response = generate(model, tokenizer, tokens)\n",
    "\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kritische Überlegungen:\n",
      "\n",
      "- \"Reconstructed\" kann in der deutschen Sprache nicht so genau übersetzt werden, da der Begriff nicht so häufig in der Finanzwelt verwendet wird. \"Wiederhergestellt\" oder \"erneut aufgebaut\" könnten als Übersetzung für \"Reconstructed\" dienen. \n",
      "- \"Prescribed\" kann als \"vorgeschrieben\" oder \"vorgeschriebene\" übersetzt werden. \n",
      "- \"Internal documentation\" kann als \"internes Dokumentation\" oder \"internes Dokument\" übersetzt werden. \n",
      "- \"Replicate\" kann als \"nachbilden\" oder \"nachbildlich machen\" übersetzt werden. \n",
      "- \"Intra-year loans\" kann als \"Zwischenjahresdarlehen\" oder \"Darlehen im Laufe eines Jahres\" übersetzt werden. \n",
      "- \"Default probability scaling\" kann als \"Ausfallwahrscheinlichkeitsskalierung\" oder \"Ausfallwahrscheinlichkeitssystem\" übersetzt werden.\n"
     ]
    }
   ],
   "source": [
    "input = \"Verbessere meine deutsche Übersetzung: Das ist der Englische Satz: Reconstructed and implemented client-prescribed mathematical models based on internal documentation to replicate default probability scaling for intra-year loans and estimate potential losses using decision trees. das ist meine übersetzung: Rekonstruktion und Implementierung von mathematischen Modellen von Kunden, basierend auf Dokumentation, um die Skalierung der Ausfallwahrscheinlichkeit für zwischenzeitliche Kredite nachzubilden und potenzielle Verluste mit Entscheidungsbäumen einzuordnen.\"\n",
    "\n",
    "print(generate_response(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged.csv\")\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.train_test_split(test_size=0.4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ds[\"train\"]\n",
    "\n",
    "eval_test_data = ds[\"test\"].train_test_split(test_size=0.3, shuffle=True)\n",
    "eval_data = eval_test_data[\"train\"]\n",
    "test_data = eval_test_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2674/2674 [00:00<00:00, 38547.57 examples/s]\n",
      "Map: 100%|██████████| 1248/1248 [00:00<00:00, 44222.56 examples/s]\n",
      "Map: 100%|██████████| 536/536 [00:00<00:00, 36973.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "INIT_PROMPT = (\n",
    "    \"Du bist ein hochentwickelter KI-Schreibassistent, der professionelle, präzise und technische Texte in \"\n",
    "    \"in Deutsch und Englisch verfasst. Falsl der Benutzer keine Sprache angibt, nutze die Sprache der Eingabe.\\n\\n\"\n",
    ")\n",
    "\n",
    "# train_data = train_data.map(lambda example: {\"inputs\": INIT_PROMPT + example[\"inputs\"]})\n",
    "# eval_data = eval_data.map(lambda example: {\"inputs\": INIT_PROMPT + example[\"inputs\"]})\n",
    "test_data = test_data.map(lambda example: {\"inputs\": INIT_PROMPT + example[\"inputs\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': 'Du bist ein hochentwickelter KI-Schreibassistent, der professionelle, präzise und technische Texte in in Deutsch und Englisch verfasst. Falsl der Benutzer keine Sprache angibt, nutze die Sprache der Eingabe.\\n\\nIt kept Anasazi from living in American Southwest by very high temparture ; it caused droughts . ',\n",
       " 'labels': 'Asasazi were kept from living in the American Southwest by very high temperatures , which often caused droughts . '}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
